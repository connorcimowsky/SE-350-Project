\documentclass[12pt]{report}

\usepackage{
    courier,
    algorithm,
    algpseudocode,
    listings,
    underscore,
    authblk,
    hyperref
}

\setlength{\parindent}{0pt}

\lstset{
    basicstyle=\ttfamily,
    breaklines=true,
    aboveskip=20pt,
    belowskip=20pt,
}

\begin{document}

\title{RTOS Documentation}

\author{
    Kathleen Chung\\
    \texttt{kklchung@uwaterloo.ca}
    \and
    Connor Cimowsky\\
    \texttt{ccimowsky@uwaterloo.ca}
    \and
    Christian De Angelis\\
    \texttt{cdeangel@uwaterloo.ca}
    \and
    Jaclyne Ooi\\
    \texttt{jpooi@uwaterloo.ca}
}

\maketitle

\tableofcontents

\listofalgorithms

\part{Design Description}

\chapter{Structural Overview}

\section{Operating System Initialization}

\subsection{Memory Initialization}

After initializing the hardware components of the MCB1700 board, such as timers and UART controllers, it is necessary to dedicate a portion of the onboard SRAM to various components of our operating system. Starting from the end address of our operating system's image, we reserve memory for structures such as process control blocks, process control queues, and the keyboard command registry. Most importantly, we divide a portion of memory into fixed-size blocks and insert them into our global memory heap.

\subsection{Process Initialization}

Once our process control structures have been initialized by our memory initialization routine, we iterate through our process initialization table and perform three tasks. First, we populate the process control block (PCB) for each process with information such as process identifier (PID) and priority. Next, we enqueue each PCB in the ready queue (unless it is an i-process, since these processes are invoked using interrupt handlers). Finally, we allocate an exception stack frame for each process and store the resulting stack pointer in the appropriate PCB. At this point, our operating system is ready to begin executing the first process by invoking \texttt{release_processor}.

\section{Memory Management}

\subsection{Heap Data Structure}

Our memory heap structure is implemented using a generic linked list. Each node in the list represents a single memory block that can be requested by invoking the \texttt{request_memory_block} primitive and released by invoking the \texttt{release_memory_block} primitive. Nodes in the memory heap are spaced apart using a predefined block size.

\subsection{Requesting Memory Blocks}

When a process invokes \texttt{request_memory_block}, the operating system first checks if any blocks are available in the heap. If the heap is empty, the kernel enqueues the caller in the blocked-on-memory queue and invokes \texttt{release_processor} so that preemption may occur. Otherwise, a pointer to the next available memory block is popped from the heap. This pointer is then incremented by a predefined offset to compensate for message envelope headers and then returned to the caller.

\subsection{Releasing Memory Blocks}

When a process invokes \texttt{release_memory_block}, the operating system first ensures that the provided address corresponds to a valid memory block. If valid, the block is then pushed onto the heap. Next, if the blocked-on-memory queue is non-empty, the highest-priority process that is blocked on memory is moved to the ready queue. Finally, \texttt{release_processor} is invoked so that the caller can be preempted if necessary.

\section{Process Management}

\subsection{Process Control Structures}

In order to fairly manage resource usage, each process in the operating system is modelled by a process control block. Each PCB contains the stack pointer, PID, priority, state, and message queue of the process it represents. Using PIDs as indices, a global array stores a pointer to each PCB for constant time access by process control primitives.\\

Our operating system maintains three queues in which PCBs are stored according to their scheduling priority. The first is the ready queue, which contains processes in the \texttt{NEW} and \texttt{READY} states. The second is the blocked-on-memory queue, which contains processes that are waiting on a memory block and are thus in the \texttt{BLOCKED_ON_MEMORY} state. The third is the blocked-on-receive queue, which contains processes that are waiting to receive a message and are thus in the \texttt{BLOCKED_ON_RECEIVE} state.

\subsection{Releasing the Processor}

Since our operating system does not employ time slicing, it is often necessary for a process to relinquish usage of the processor. This mechanism is provided by our operating system and can be employed by invoking the \texttt{release_processor} primitive.\\

When invoked, this primitive uses the scheduler to determine which process should be executed next. To do this, the scheduler iterates through the ready queue in order of decreasing priority, exercising a first-in first-out (round-robin) scheduling policy for processes of the same priority.\\

Once a process has been selected by the scheduler, a context switch will only occur if its priority is greater than or equal to that of the currently executing process. Otherwise, the caller will resume execution.\\

In order to perform a context switch, the context of the current process (i.e., the current stack pointer) must be saved to its process control block. Next, the context of the selected process is restored (i.e., its stack pointer is restored). When the saved registers are popped from the stack pointer of the selected process, execution will resume at the point where it left off.

\begin{algorithm}
\caption{Releasing the Processor}
\begin{algorithmic}[1]
\Procedure {k_release_processor}{\null}
    \If {$ready\_queue$ is empty}
        \State \Return \texttt{RTOS_OK} \Comment{Do nothing if the ready queue is empty}
    \EndIf
    \State $next\_proc \leftarrow \Call{k\_dequeue\_ready\_process}{\null}$ \Comment{Invoke the scheduler}
    \If {$cur\_proc.state \not = \texttt{BLOCKED}$}
        \If {$next\_proc.priority > cur\_proc.priority$}
            \State \Return \texttt{RTOS_OK} \Comment{Do nothing if the priority is lower}
        \EndIf
    \EndIf
    \State \Call{k\_context\_switch}{$cur\_proc$, $next\_proc$}
    \State \Return \texttt{RTOS_OK}
\EndProcedure

\Statex

\Procedure {k_dequeue_ready_process}{\null}
    \For{$i \leftarrow 0$ \textbf{to} \texttt{NUM_PRIORITIES}}
        \If{$ready\_queue[i]$ is not empty}
            \State \Return $\Call{dequeue}{ready\_queue[i]}$
        \EndIf
    \EndFor
    \State \Return \texttt{NULL}
\EndProcedure
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Context Switching}
\begin{algorithmic}[1]
\Procedure {k_context_switch}{$prev\_proc$, $next\_proc$}
    \If{$next\_proc.state \not = \texttt{NEW}$ \textbf{and} $next\_proc.state \not = \texttt{READY}$}
        \State \Return \Comment{Do nothing if $next\_proc$ is unable to execute}
    \EndIf
    \If{$prev\_proc.state = \texttt{EXECUTING}$}
        \State $prev\_proc.state \leftarrow \texttt{READY}$
        \State $\Call{k_enqueue_ready_process}{prev\_proc}$
    \EndIf
    \State $prev\_proc.sp \leftarrow \Call{\_\_get\_msp}{\null}$
    \State $next\_proc.state \leftarrow \texttt{EXECUTING}$
    \State $\Call{\_\_set\_msp}{next\_proc.sp}$
    \If{$next\_proc.state = \texttt{NEW}$}
        \State \Call{__rte}{\null} \Comment{For new processes, pop the exception stack frame}
    \EndIf
\EndProcedure
\end{algorithmic}
\end{algorithm}

\subsection{Process Priority}

Each process has a priority which is stored in its PCB. This priority is used to enforce correct precedence during scheduling, blocking, and preemption operations.\\

Our operating system allows processes to retrieve and modify the scheduling priority of themselves or other processes by providing two primitives: \texttt{get_process_priority} and \texttt{set_process_priority}. If a process's priority is changed while it resides in a process control queue, it is removed and then reinserted into the queue corresponding to its new priority. The \texttt{release_processor} primitive is then invoked to ensure that preemption will occur if necessary.

\begin{algorithm}
\caption{Process Priority}
\begin{algorithmic}[1]
\Procedure {k_get_process_priority}{$proc$}
    \If {$proc.pid$ is invalid}
        \State \Return \texttt{RTOS_ERR}
    \EndIf
    \State \Return $proc.priority$
\EndProcedure

\Statex

\Procedure {k_set_process_priority}{$proc$, $priority$}
    \If{$proc.pid$ is invalid \textbf{or} $priority$ is invalid}
        \State \Return \texttt{RTOS_ERR}
    \EndIf
    \If{$proc.priority = priority$}
        \State \Return \texttt{RTOS_OK} \Comment{Do nothing if the priority is unchanged}
    \EndIf
    \If{$proc.state = \texttt{NEW}$ \textbf{or} $proc.state = \texttt{READY}$}
        \State \Call{remove_from_queue}{$proc$, $ready\_queue$}
        \State $proc.priority \leftarrow priority$
        \State \Call{k_enqueue_ready_process}{$proc$}
    \ElsIf{$proc.state = \texttt{BLOCKED_ON_MEMORY}$}
        \State \Call{remove_from_queue}{$proc$, $blocked\_on\_memory\_queue$}
        \State $proc.priority \leftarrow priority$
        \State \Call{k_enqueue_blocked_on_memory_process}{$proc$}
    \ElsIf{$proc.state = \texttt{BLOCKED_ON_RECEIVE}$}
        \State \Call{remove_from_queue}{$proc$, $blocked\_on\_receive\_queue$}
        \State $proc.priority \leftarrow priority$
        \State \Call{k_enqueue_blocked_on_receive_process}{$proc$}
    \Else
        \State $proc.priority \leftarrow priority$
    \EndIf
    \State \Call{k_release_processor}{\null}
    \State \Return \texttt{RTOS_OK}
\EndProcedure
\end{algorithmic}
\end{algorithm}

\subsection{Interprocess Communication}

Messages are sent between processes using message envelopes. Each PCB has a `mailbox', implemented as a queue of message envelopes.\\

There are two structures used to represent messages: a kernel-facing message header containing the information required for communication, and a user-facing message envelope which contains only the data that is relevant to the sender and recipient. The header includes the PID of the sender, the PID of the recipient, and an expiry time. The user-facing envelope only contains the message type and the message data itself.\\

When a process wishes to send a message, it will first invoke \texttt{request_memory_block} for the envelope. It then populates the message envelope fields and invokes \texttt{send_message}. This primitive populates the message header fields and enqueues the message in the recipient's message queue. If necessary, the recipient will be unblocked and \texttt{release_processor} will be invoked so that preemption may occur; otherwise, control will be returned to the caller.\\

\begin{algorithm}
\caption{Sending Messages}
\begin{algorithmic}[1]
\Procedure {k_send_message}{$recipient$, $msg$}
    \If {$recipient.pid$ is invalid}
        \State \Return \texttt{RTOS_ERR}
    \EndIf
    \If {\Call{k_send_message_helper}{$cur\_proc$, $recipient$, $msg$} $= 1$}
        \If {$recipient.priority \le cur\_proc.priority$}
            \State \Return \Call{k_release_processor}{\null}
        \EndIf
    \EndIf
    \State \Return \texttt{RTOS_OK}
\EndProcedure

\Statex

\Procedure {k_send_message_helper}{$sender$, $recipient$, $msg$}
    \State $msg.sender \leftarrow sender$
    \State $msg.recipient \leftarrow recipient$
    \State \Call{enqueue}{$msg$, $recipient.msg\_queue$}
    \If {$recipient.state = \texttt{BLOCKED_ON_RECEIVE}$}
        \State \Call{remove_from_queue}{$recipient$, $blocked\_on\_receive\_queue$}
        \State $recipient.state \leftarrow \texttt{READY}$
        \State \Call{k_enqueue_ready_process}{$recipient$}
        \State \Return 1 \Comment{1 indicates that the recipient was unblocked}
    \Else
        \State \Return 0
    \EndIf
\EndProcedure
\end{algorithmic}
\end{algorithm}

The procedure for delayed message sending is similar, with the added requirement that an expiration time is included in the header. Instead of directly enqueueing the message in the recipient's message queue, \texttt{delayed_send} enqueues the message in the timer i-process's message queue. As described in Section \ref{subsec:Timer I-Process}, the timer i-process will then take care of dispatching the message at the correct time.\\

\begin{algorithm}
\caption{Sending Delayed Messages}
\begin{algorithmic}[1]
\Procedure {k_delayed_send}{$recipient$, $msg$, $delay$}
    \If {$recipient.pid$ is invalid}
        \State \Return \texttt{RTOS_ERR}
    \EndIf
    \State $msg.expiry \leftarrow cur\_time + delay$
    \State $msg.sender \leftarrow cur\_proc$
    \State $msg.recipient \leftarrow recipient$
    \State \Call{enqueue}{$msg$, $timer\_i\_proc.msg\_queue$}
    \State \Return \texttt{RTOS_OK}
\EndProcedure
\end{algorithmic}
\end{algorithm}

When a process invokes \texttt{receive_message}, the next message will be dequeued from its message queue and returned, as long as there is at least one pending message in the queue. Otherwise, the process is placed in the blocked-on-receive queue and preempted using \texttt{release_processor}.\\

\begin{algorithm}
\caption{Receiving Messages}
\begin{algorithmic}[1]
\Procedure {k_receive_message}{$sender$}
    \While{$cur\_proc.msg\_queue$ is empty}
        \State \Call{k_enqueue_blocked_on_receive_process}{$cur\_proc$}
        \State \Call{k_release_processor}{\null}
    \EndWhile
    \State $msg \leftarrow \Call{dequeue}{cur\_proc.msg\_queue}$
    \State $sender \leftarrow msg.sender$
    \State \Return $msg$
\EndProcedure
\end{algorithmic}
\end{algorithm}

\section{System Processes}

\subsection{Null Process}

The null process has the lowest priority of any process in our operating system. Since the processor must always be busy, the null process acts as a fail­-safe for situations when no other process can be scheduled for execution. As such, the null process simply invokes \texttt{release_processor} in an infinite loop, allowing other processes to be scheduled as soon as they are ready.

\subsection{KCD Process}

The Keyboard Command Decoder (KCD) process provides a console-like mechanism to users of our operating system. Upon receipt of a command registration message from another process (retrieved using \texttt{receive_message}), it uses a global registry to associate the specified command with the message sender. This registry is implemented as a linked list of structures which contain a command identifier string and the PID of the registered process. Each time a line of input is entered through the console, the KCD process uses the registry to determine if it is prefixed with a registered command; if so, the input is forwarded to the process specified in the registry entry using \texttt{send_message} so that it may act upon the command.

\subsection{CRT Process}

The purpose of the CRT process is to print text to the system console. In order to achieve this, it repeatedly invokes \texttt{receive_message} and forwards received messages to the UART i-process using \texttt{send_message}. After it does this, it triggers a UART output interrupt so that the UART i-process may execute. The mechanism by which the UART i-process achieves interrupt-driven output is outlined in Section \ref{subsec:UART I-Process}.

\section{Interrupt Processes}

\subsection{Timer I-Process}
\label{subsec:Timer I-Process}

The timer i-process provides timing services to our operating system and is primarily responsible for dispatching delayed messages (sent using \texttt{delayed_send}) to other processes. This is achieved through the use of message queues and a global counter, which is used for keeping track of the system time.\\

When a timer interrupt occurs (once every millisecond), the timer i-process is invoked by the timer interrupt handler. First, it checks if there are any messages in its message queue. If there is a message, it is added to the timeout queue, which maintains sorted order with respect to the expiry times of contained messages. Next, it iterates through the timeout queue and places any expired messages in the message queues of the appropriate recipients. If a message was delivered to a process of equal or greater priority than the current process, the operating system will preempt to the recipient by invoking \texttt{release_processor}.

\subsection{UART I-Process}
\label{subsec:UART I-Process}

The UART i-process acts as an interface between the system console and other processes in our operating system. It is triggered by two types of interrupts, each corresponding to one of the two tasks performed by this process.\\

The first responsibility of the UART i-process is handling user input. To facilitate this, a global input buffer is used. When the user presses the return key, this buffer is copied into a message which is then sent to the KCD process for interpretation using a non-preemptive version of \texttt{send_message}.\\

When an output interrupt occurs, the UART i-process retrieves the next message in its queue using a non-blocking version of \texttt{receive_message}. It then uses repeated interrupts to sequentially print characters of the message until it reaches the end.

\section{User Processes}

\subsection{Wall Clock Process}

The wall clock process uses \texttt{delayed_send} to display a digital clock that updates every second. The process sends itself messages with a delay of one second,
triggering ``tick" updates. Each time the clock ticks, a message is sent to the CRT process using \texttt{send_message} to display the current wall clock time. On startup, the wall clock process registers keyboard commands with the KCD process which allow the time to be set, reset, and stopped.

\subsection{Test Processes}

In order to ensure the correct behaviour of our operating system, we use six user-­level test processes to invoke kernel primitives and check for any incorrect results. These test processes use global variables to coordinate with each other and ensure that  our operating system works as expected. Some of the key mechanisms that are tested include preemption, modification of process priority, memory block assignment, interprocess communication, and system processes such as the KCD and CRT processes.

\part{Lessons Learned}

\chapter{Bugs and Design Decisions}

\section{Data storage in our linked structures}

From the beginning of our project, we knew that we would need to store different types of data in linked structures for different use cases. For example, we knew that nodes in our memory heap structure would have different data storage requirements compared to nodes in our process control structures (e.g. ready queue, blocked queue).\\

Since we wanted to avoid creating linked structures that were coupled with the type of data they were storing, we needed to devise a way to make them as generic as possible.\\

We chose to make a generic node structure, \texttt{node_t}, with only one member: a pointer to the next \texttt{node_t}:

\begin{minipage}{\textwidth}
\begin{lstlisting}[language=C]
typedef struct node_t {
    struct node_t *p_next;
} node_t;
\end{lstlisting}
\end{minipage}

We then designed our linked structures to accommodate nodes of this type:

\begin{minipage}{\textwidth}
\begin{lstlisting}[language=C]
typedef struct list_t {
    node_t *p_first;
} list_t;

typedef struct queue_t {
    node_t *p_first;
    node_t *p_last;
} queue_t;
\end{lstlisting}
\end{minipage}

This way, if a certain use case necessitates having additional storage in each node, we can simply declare a new type with the additional required members. For example, here is a node that can store a pointer to a process control block:

\begin{minipage}{\textwidth}
\begin{lstlisting}[language=C]
typedef struct k_pcb_node_t {
    struct k_pcb_node_t *p_next;
    k_pcb_t *p_pcb;
} k_pcb_node_t;
\end{lstlisting}
\end{minipage}

As long as the first member remains a pointer to the next node, the structure members will line up in memory and our linked structures will accommodate these nodes (assuming we cast \texttt{k_pcb_node_t} pointers to \texttt{node_t} pointers on insertion, and vice versa on removal).

\section{Modeling blocks in our memory heap}

During the planning phase, we chose to implement our memory heap as a linked list. However, we were not sure how nodes in this linked list should keep track of the blocks that they would represent.\\

In addition to having a pointer to the next node, our first thought was that each node structure should have a pointer to the beginning address of the memory block that it represents:

\begin{minipage}{\textwidth}
\begin{lstlisting}[language=C]
typedef struct k_mem_blnode_t {
    struct k_mem_blnode_t *p_next;
    void *p_mem_blk_start_addr;
} k_mem_blnode_t;
\end{lstlisting}
\end{minipage}

After further thought, we realized that since the size of each memory block is known at compile time, we can simply space the nodes apart at \texttt{(sizeof(node_t) + BLOCK_SIZE)} intervals, obviating the need for a member such as \texttt{void *p_mem_blk_start_addr}. Thus, we were able to use the unmodified node structure (\texttt{node_t}, outlined in the previous section) for our memory heap.

\section{Pointer arithmetic}

For our memory heap, we chose to structure blocks with the header in front of the block itself. This means that when we remove a node from our heap in \texttt{k_request_memory_block()}, we need to increment \texttt{node}'s address by 4 bytes (the size of the header, \texttt{sizeof(node_t)}) before returning the address to the user. Similarly, in \texttt{k_release_memory_block(void *p_mem_blk)}, we need to decrement the address of \texttt{p_mem_blk} by 4 bytes in order to get the correct pointer to the node for re-insertion into the heap.\\

When we originally implemented this pointer arithmetic in \texttt{k_request_memory_block()}, we did the following:

\begin{minipage}{\textwidth}
\begin{lstlisting}[language=C]
node_t *p_mem_blk = get_node(gp_heap);
p_mem_blk += sizeof(node_t);
\end{lstlisting}
\end{minipage}

If the value of \texttt{p_mem_blk} is, for example, \texttt{0x10000000}, we would expect the resulting value to be \texttt{0x10000004}. However, the above code produces a result of \texttt{0x10000010}. This is because the compiler knows the size of \texttt{node_t}, and is multiplying the addend by \texttt{sizeof(node_t)}, resulting in an addend of 16 instead of 4. Therefore, we revised the addend to 1 instead of 4:

\begin{minipage}{\textwidth}
\begin{lstlisting}[language=C]
node_t *p_mem_blk = get_node(gp_heap);
p_mem_blk += 1;
\end{lstlisting}
\end{minipage}

Since the block pointer we receive in \texttt{k_request_memory_block(void *p_mem_blk)} is not typed as a \texttt{node_t}, the compiler does not multiply the subtrahend by \texttt{sizeof(node_t)} for us. Instead of doing this multiplication ourselves, we chose to cast \texttt{p_mem_blk} as a pointer to a \texttt{node_t} and simply use a subtrahend of 1:

\begin{minipage}{\textwidth}
\begin{lstlisting}[language=C]
node_t *p_blk = p_mem_blk;
p_blk -= 1;
\end{lstlisting}
\end{minipage}

This will correctly subtract the size of our header from the address of the returned block.

\section{Context switching}

In order to context-switch to processes that have not yet executed, it is necessary to pop a pre-made exception stack frame off of the stack (by calling the inline assembly function \texttt{__rte()}) so that the new process has an initial context.\\

Since we only want to call \texttt{__rte()} if a process has not executed before, we needed to add another process state, \texttt{NEW}. This gives us more fine-grained process control behavior for \texttt{NEW} vs. \texttt{READY} processes.

\section{Process control blocks}

At the beginning of our \texttt{memory_init()} function, we allocate an array of process control block (PCB) nodes (\texttt{k_pcb_node_t}), one for each process (\texttt{NUM_TEST_PROCS}). Since this is an array, it is indexed in array notation (\texttt{0} to \texttt{NUM_TEST_PROCS-1}).\\

When we need to access a PCB node for an arbitrary process, \texttt{p_process}, it makes sense to access this array using the process identifier (\texttt{p_process->m_pid}). However, in our original implementation, process identifiers did not begin at 0; they began at 1. So, in order to access the PCB node for \texttt{p_process}, we needed to access our array of PCB nodes at index \texttt{(p_process->m_pid-1)}. We have since changed our indexing of PIDs (so that the null process can always have a PID of 0), so this is no longer a problem. Although this is a simple concept, it took an extraordinary amount of time to debug.

\section{Dequeuing from the ready queue}

In \texttt{request_memory_block()}, it is expected that the calling process may become blocked in the case that there is no available memory in the heap.\\

Originally, our implementation of \texttt{k_request_memory_block()} would attempt to dequeue the calling process from the ready queue and enqueue it in the blocked queue. This conceptually made sense, as it should be in the \texttt{BLOCKED_ON_RESOURCE} state, not the \texttt{READY} state, next time we call \texttt{k_release_processor()}.\\

However, we know that if a process is able to call \texttt{request_memory_block()}, then it must currently be in the \texttt{EXECUTING} state. Thus, it must have already been dequeued from the ready queue in order to have been scheduled in the first place. So, all we need to do when out of memory is add the calling process to the blocked queue:

\begin{minipage}{\textwidth}
\begin{lstlisting}[language=C]
while (is_list_empty(gp_heap)) {
    // no available memory in the heap
    if (k_enqueue_blocked_process(gp_current_process) == RTX_OK) {
        k_release_processor();
    }
}
\end{lstlisting}
\end{minipage}

\section{Dynamic allocation in the kernel}

In our initial implementation of the kernel, we dynamically requested and returned heap memory for PCB nodes as we enqueued and dequeued them from the ready and blocked queues. For na\"{i}ve test processes, this was not a problem.\\

Once we started to request memory blocks in our test processes, we noticed a fatal flaw in this approach. If a process attempted to request a memory block when there was no available memory in the heap, we would attempt to add it to the blocked queue, as shown in the previous section.\\

However, since we were dynamically requesting heap memory for PCB nodes to be enqueued in the blocked queue (by calling \texttt{k_request_memory_block()}), we would never succeed in enqueueing the process in the blocked queue. Instead, we would infinitely recurse into \texttt{k_request_memory_block()}.\\

To solve this problem, we decided to statically allocate all of our PCB nodes in \texttt{memory_init()}, obviating the need to dynamically request memory in the kernel:

\begin{minipage}{\textwidth}
\begin{lstlisting}[language=C]
/* allocate memory for pcb node pointers */
gp_pcb_nodes = (k_pcb_node_t **)p_end;
p_end += NUM_TEST_PROCS * sizeof(k_pcb_node_t *);

/* allocate memory for each pcb node */
for (i = 0; i < NUM_TEST_PROCS; i++) {
    gp_pcb_nodes[i] = (k_pcb_node_t *)p_end;
    p_end += sizeof(k_pcb_node_t); 
}
\end{lstlisting}
\end{minipage}

\end{document}
